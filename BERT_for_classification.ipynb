{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "BERT_for_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e975997045e34db398d95f9adce032df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1043a043d264e39bdf5882085ca7f1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce363b31476a4acaa6f5953dfebf4023",
              "IPY_MODEL_ea011ca4c5724c0ca48e98fda634c9e6"
            ]
          }
        },
        "e1043a043d264e39bdf5882085ca7f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce363b31476a4acaa6f5953dfebf4023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_928d2abc37e14c03a16c1c8b69fdec9a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb30ca8da65a48869f38839d75c9bedc"
          }
        },
        "ea011ca4c5724c0ca48e98fda634c9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f29ff48addb4f9597e0460068933942",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.43MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0d93561cce44d4f8e0a1b2fb8e48a16"
          }
        },
        "928d2abc37e14c03a16c1c8b69fdec9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb30ca8da65a48869f38839d75c9bedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f29ff48addb4f9597e0460068933942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0d93561cce44d4f8e0a1b2fb8e48a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37876a2ec60a44af94dd8ab3e4079be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f88f56a43eb4ada9a20b69430f25c84",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d1154c8f1334c9ab48b42902f284829",
              "IPY_MODEL_1a3d3d5da9e04390bd5e0ab64c6fd9df"
            ]
          }
        },
        "7f88f56a43eb4ada9a20b69430f25c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d1154c8f1334c9ab48b42902f284829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_debe4481017b4088ae3fa548980f5959",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2c0af1d01cd4e6eb5bb6d252a213794"
          }
        },
        "1a3d3d5da9e04390bd5e0ab64c6fd9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4b5c56e4f1040e5a2eda87973aa6da4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:14&lt;00:00, 30.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9a4f4d18c174a1c9765b71ce03cf9a4"
          }
        },
        "debe4481017b4088ae3fa548980f5959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2c0af1d01cd4e6eb5bb6d252a213794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4b5c56e4f1040e5a2eda87973aa6da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9a4f4d18c174a1c9765b71ce03cf9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a80a87fb9917495c8ceee704cacdaec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a752a634ff6247d1bf933284d3c705b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8e9d47f660674404be31de12e74baff6",
              "IPY_MODEL_4e8768d158e346cc8ed560dbd17f372f"
            ]
          }
        },
        "a752a634ff6247d1bf933284d3c705b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e9d47f660674404be31de12e74baff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24bcb506a97d4ce8878d4078a6be2f00",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_956ae416a1b045139e96aca8141a4561"
          }
        },
        "4e8768d158e346cc8ed560dbd17f372f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9892c53bf3143719dc4514e5f5c2737",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 43.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e56a5f45dacf46f9a1e357a1fa7452a1"
          }
        },
        "24bcb506a97d4ce8878d4078a6be2f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "956ae416a1b045139e96aca8141a4561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9892c53bf3143719dc4514e5f5c2737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e56a5f45dacf46f9a1e357a1fa7452a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonghoonleeee/Natural-Language-Process/blob/master/BERT_for_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWmuv8wwoi5X",
        "colab_type": "text"
      },
      "source": [
        "# [SEP 592] BERT Fine-Tuning Tutorial with PyTorch\n",
        "\n",
        "Primary TA: 이영준\n",
        "\n",
        "Mobile: +82-10-5039-2961\n",
        "\n",
        "TA's E-mail: passing2961@gmail.com, yj2961@kaist.ac.kr\n",
        "\n",
        "Lab Homepage: https://keai.kaist.ac.kr/\n",
        "\n",
        "본 실습에서는 `huggingface` PyTorch 라이브러리를 이용하여 sentiment classification에서 BERT 를 어떻게 fine-tuning 하는지에 대한 부분을 설명합니다. 또한, BERT 모델을 fine-tuning 하기 위해 amazon review 데이터를 사용합니다. \n",
        "\n",
        "## Introduction\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/cv.png?raw=true\" width=\"80%\" height=\"80%\" title=\"cv\" alt=\"cv\"></img></center>\n",
        "\n",
        "[VGGNet]: https://arxiv.org/pdf/1409.1556\n",
        "[GoogLeNet]: https://arxiv.org/pdf/1409.4842\n",
        "[ResNet]: https://arxiv.org/abs/1512.03385\n",
        "\n",
        "[word2vec]: https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\n",
        "[GloVe]: https://www.aclweb.org/anthology/D14-1162\n",
        "[fastText]: https://arxiv.org/abs/1607.04606\n",
        "\n",
        "[Semi-Supervised Sequence Learning]: https://arxiv.org/abs/1511.01432\n",
        "[ELMo]: https://arxiv.org/abs/1802.05365\n",
        "[OpenAI GPT]: https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf\n",
        "\n",
        "Computer vision (CV) 분야에서는 [VGGNet], [GoogLeNet], [ResNet] 과 같은 pre-train 된 모델을 이용하여 다른 downstream task 에 적용하는 transfer learning 이 활발히 이루어지고 있습니다. Natural Language Processing (NLP) 분야에서도 [word2vec], [GloVe], [fastText] 와 같은 pre-trained word embedding 이 다른 downstream task 에 사용되어왔습니다. 그러나, 기존에 word embedding 연구들은 contextual language representation 의 표현이 어려웠습니다. 이를 해결하기 위해, 최근 연구들은 pre-trained language model 을 사용하였고, Google 의 [Semi-Supervised Sequence Learning] 연구를 시작으로 [ELMo], [OpenAI GPT] 등 다양한 모델들이 제안되었습니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/bert.png?raw=true\" width=\"80%\" height=\"80%\" title=\"bert_glue\" alt=\"bert_glue\"></img></center>\n",
        "\n",
        "[BERT]: https://arxiv.org/abs/1810.04805\n",
        "\n",
        "그러나, 기존의 연구들은 left context 혹은 right context 로만 진행하는 unidirectional 합니다. 그렇지만, language 를 더 잘 이해하기 위해서는 bidirectional 해야합니다. 즉, language understanding 을 더 향상시키기 위해 [BERT] (Bidirectional Encoder Representations from Transformers) 라는 모델이 제안되었습니다. \n",
        "\n",
        "여기서 중요한 이슈는 **language model 이 bidirectional 하게되면, 단어가 간접적으로 자기 자신을 보게 되는 문제**가 발생합니다. 아래의 그림을 보시면 알 수 있습니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/multi_bert.png?raw=true\" width=\"50%\" height=\"50%\" title=\"\" alt=\"cv\"></img></center>\n",
        "\n",
        "이를 해결하기 위해, BERT 를 학습시킬 때는 **Masked Language Model** 을 이용하여 학습을 진행합니다. 추가로, 문장들 사이에 relationship 을 학습시키기 위해 **Next Sentence Prediction task** 를 사용합니다. 자세한 내용은 논문에 가시면 확인하실 수 있습니다. \n",
        "\n",
        "- pre-training: **Maksed Language Model + Next Sentence Prediction** + *Wikepedia + BookCorpus*\n",
        "- fine-tuning: GLUE tasks (NLU downstream tasks)\n",
        "[GLUE]: https://gluebenchmark.com/leaderboard\n",
        "\n",
        "논문에서도 알 수 있듯이, BERT 는 [GLUE] 라는 자연어 이해 (Language Understanding) benchmark 에서 높은 성능을 기록하였습니다. GLUE 는 자연어 이해 관련 11개의 task 를 포함하고 있습니다.\n",
        "(*GLUE paper: https://arxiv.org/abs/1804.07461*)\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/bert_glue_1.png?raw=true\"  title=\"bert_glue\" alt=\"bert_glue\"></img></center>\n",
        "\n",
        "*이미지 출처: https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html*\n",
        "\n",
        "\n",
        "\n",
        "__본 실습에서는 pre-train 된 BERT 모델을 가져와서 amazon review 데이터를 이용하여 sentiment classification 을 진행할 것입니다.__\n",
        "\n",
        "## Documentation\n",
        "\n",
        "본 실습 자료를 위해 참고한 자료는 아래와 같습니다.\n",
        "\n",
        "- Chris McCormick's tutorial: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "- huggingface github: https://github.com/huggingface/transformers\n",
        "- huggingface documentation: https://huggingface.co/transformers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tZo8B6eVJFf",
        "colab_type": "text"
      },
      "source": [
        "## Step 0: Connect to Google drive\n",
        "\n",
        "- 학습 도중 checkpoint 를 저장해서 나중에 불러와서 사용하고 싶은 경우에 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omfN5AZ9ys_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "24f05742-92c4-4998-c6a9-3fbf85c91ac2"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QhEGRaVVaFh",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYhj-RIeybIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "74abfdbd-ce93-4958-8e92-5bca6a058dd9"
      },
      "source": [
        "import pickle as pc\n",
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "\n",
        "# torch 버전 확인\n",
        "print(\"Pytorch Version: \", torch.__version__)\n",
        "\n",
        "# GPU 사용 가능한지 여부 확인\n",
        "if torch.cuda.is_available():\n",
        "    \n",
        "    # PyTorch 에게 GPU 사용할거라고 알려주기\n",
        "    device = torch.device(\"cuda\")\n",
        "    \n",
        "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
        "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch Version:  1.5.0+cu101\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DoBvLNQV3wj",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Installing the Hugging Face Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrMn70gSV3Ko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "b778f229-3142-4710-e4b9-c12786fb93de"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\r\u001b[K     |▌                               | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 3.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 665kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=28c2d0da3c3cde11f77ec922292e9b672e18105aac5f300ad41fe175acb59c7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1wW8UouVh8M",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Configure the experiments\n",
        "\n",
        "- 모델의 실험(학습 및 평가)을 필요한 파라미터 및 인자 설정\n",
        "    - Hyperparameter: hidden unit size, vocabulary size, max length, dropout rate 등\n",
        "    - Argument: file directory 등\n",
        "\n",
        "*Note: 해당 실습 자료에서는 데이터 경로만 지정*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_4QT4BDybIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_filename = '/content/gdrive/My Drive/Colab Notebooks/data/train_data_all.csv'\n",
        "test_data = '/content/gdrive/My Drive/Colab Notebooks/data/balanced_data'\n",
        "test_label = '/content/gdrive/My Drive/Colab Notebooks/data/balanced_label'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRSvzQwfWFzo",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Load Amazon Review Dataset\n",
        "\n",
        "- `load_data`: amazon review data 에서 **[reviewText, label]** 형태로 데이터를 불러오는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1In5hQtPybIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "    data = list()\n",
        "    label = list()\n",
        "    \n",
        "    f = open(filename, 'r', encoding='utf-8')\n",
        "    reader = csv.reader(f)\n",
        "    for idx, line in enumerate(reader):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "\n",
        "        data.append(line[5])\n",
        "        label.append(int(line[2]))\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    # data 랑 label 사이즈 일치 여부 확인\n",
        "    assert len(data) == len(label)\n",
        "    return data, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBIeV1TybIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, train_label = load_data(train_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43O3FuU7ybI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d3c9a83a-1b0b-4bb0-bb8a-1c89a7c05686"
      },
      "source": [
        "print(\"Size of train data: {}\".format(len(train_data)))\n",
        "print(\"Size of train label: {}\".format(len(train_label)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train data: 10727\n",
            "Size of train label: 10727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23USqxBAybJA",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Tokenization & Input Formatting\n",
        "\n",
        "본 단계에서는 BERT 가 학습한 format 에 맞게 amazon review dataset 을 변환해줍니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l00cRz_EybJC",
        "colab_type": "text"
      },
      "source": [
        "### Step 5-1: BERT Tokenizer\n",
        "\n",
        "BERT 모델에 text 를 입력으로 주기 위해서는 BERT 에서 사용한 tokenizer 를 이용하여 text 를 token 단위로 나누고, 각 token 들을 특정 index 로 mapping 시켜줍니다. \n",
        "\n",
        "- `BertTokenizer`: punctuation splitting + wordpiece\n",
        "  - `bert-base-uncased`: 2-layer, 768-hidden, 12-heads, 110M parameters. Trained on **lower-cased** English text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kks51eZ9ybJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "e975997045e34db398d95f9adce032df",
            "e1043a043d264e39bdf5882085ca7f1e",
            "ce363b31476a4acaa6f5953dfebf4023",
            "ea011ca4c5724c0ca48e98fda634c9e6",
            "928d2abc37e14c03a16c1c8b69fdec9a",
            "fb30ca8da65a48869f38839d75c9bedc",
            "2f29ff48addb4f9597e0460068933942",
            "d0d93561cce44d4f8e0a1b2fb8e48a16"
          ]
        },
        "outputId": "f4a7720d-c65f-4dfc-9f67-13276586036d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# BERT tokenizer 불러오기\n",
        "print(\"Loading BERT tokenizer...\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e975997045e34db398d95f9adce032df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTwSHYz1ybJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1ab2473f-23c6-4137-bf68-217b41bcbe4c"
      },
      "source": [
        "# 하나의 sentence 에 대해 BertTokenizer 적용\n",
        "\n",
        "# Print the original sentence.\n",
        "print(\"Original: \", train_data[0])\n",
        "print()\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print(\"Tokenized: \", tokenizer.tokenize(train_data[0]))\n",
        "print()\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print(\"Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_data[0])))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  I never thought that I would find the right moisturizer for my skin. I have combination skin with large pores that get gunked up if I neglect them and I ve struggled for some time to find a product that would provide sufficient moisture without breaking me out or turning my face into an oil-slick. This is truly a holy grail moisturizer for me and has a nice face feel and natural herbal scent. Will definitely repurchase!  I m a 30 something multi-ethnic muxer and a recent convert to korean beauty. This is my new routine and my skin has never felt or looked bettter!  1) Banila Co Clean It Zero Reservatrol 2) Neogen Green Tea Real Fresh Foam Cleanser 3) MISSHA Time Revolution First Treatment Essence (Morning) or MISSHA Time Revolution Night Repair New Science Ampoule (Night) 4) Cosrx Oil-Free Ultra-Moisturizing Lotion (Morning and ever OTHER night) or Cosrx Ultimate Nourishing Rice Overnight Mask\n",
            "\n",
            "Tokenized:  ['i', 'never', 'thought', 'that', 'i', 'would', 'find', 'the', 'right', 'moist', '##uri', '##zer', 'for', 'my', 'skin', '.', 'i', 'have', 'combination', 'skin', 'with', 'large', 'por', '##es', 'that', 'get', 'gun', '##ked', 'up', 'if', 'i', 'neglect', 'them', 'and', 'i', 've', 'struggled', 'for', 'some', 'time', 'to', 'find', 'a', 'product', 'that', 'would', 'provide', 'sufficient', 'moisture', 'without', 'breaking', 'me', 'out', 'or', 'turning', 'my', 'face', 'into', 'an', 'oil', '-', 'slick', '.', 'this', 'is', 'truly', 'a', 'holy', 'gr', '##ail', 'moist', '##uri', '##zer', 'for', 'me', 'and', 'has', 'a', 'nice', 'face', 'feel', 'and', 'natural', 'herbal', 'scent', '.', 'will', 'definitely', 'rep', '##ur', '##chase', '!', 'i', 'm', 'a', '30', 'something', 'multi', '-', 'ethnic', 'mu', '##x', '##er', 'and', 'a', 'recent', 'convert', 'to', 'korean', 'beauty', '.', 'this', 'is', 'my', 'new', 'routine', 'and', 'my', 'skin', 'has', 'never', 'felt', 'or', 'looked', 'bet', '##tter', '!', '1', ')', 'ban', '##ila', 'co', 'clean', 'it', 'zero', 'res', '##er', '##vat', '##rol', '2', ')', 'neo', '##gen', 'green', 'tea', 'real', 'fresh', 'foam', 'clean', '##ser', '3', ')', 'miss', '##ha', 'time', 'revolution', 'first', 'treatment', 'essence', '(', 'morning', ')', 'or', 'miss', '##ha', 'time', 'revolution', 'night', 'repair', 'new', 'science', 'amp', '##ou', '##le', '(', 'night', ')', '4', ')', 'co', '##sr', '##x', 'oil', '-', 'free', 'ultra', '-', 'moist', '##uri', '##zing', 'lot', '##ion', '(', 'morning', 'and', 'ever', 'other', 'night', ')', 'or', 'co', '##sr', '##x', 'ultimate', 'no', '##uri', '##shing', 'rice', 'overnight', 'mask']\n",
            "\n",
            "Token IDs:  [1045, 2196, 2245, 2008, 1045, 2052, 2424, 1996, 2157, 11052, 9496, 6290, 2005, 2026, 3096, 1012, 1045, 2031, 5257, 3096, 2007, 2312, 18499, 2229, 2008, 2131, 3282, 8126, 2039, 2065, 1045, 19046, 2068, 1998, 1045, 2310, 6915, 2005, 2070, 2051, 2000, 2424, 1037, 4031, 2008, 2052, 3073, 7182, 14098, 2302, 4911, 2033, 2041, 2030, 3810, 2026, 2227, 2046, 2019, 3514, 1011, 13554, 1012, 2023, 2003, 5621, 1037, 4151, 24665, 12502, 11052, 9496, 6290, 2005, 2033, 1998, 2038, 1037, 3835, 2227, 2514, 1998, 3019, 27849, 6518, 1012, 2097, 5791, 16360, 3126, 26300, 999, 1045, 1049, 1037, 2382, 2242, 4800, 1011, 5636, 14163, 2595, 2121, 1998, 1037, 3522, 10463, 2000, 4759, 5053, 1012, 2023, 2003, 2026, 2047, 9410, 1998, 2026, 3096, 2038, 2196, 2371, 2030, 2246, 6655, 12079, 999, 1015, 1007, 7221, 11733, 2522, 4550, 2009, 5717, 24501, 2121, 22879, 13153, 1016, 1007, 9253, 6914, 2665, 5572, 2613, 4840, 17952, 4550, 8043, 1017, 1007, 3335, 3270, 2051, 4329, 2034, 3949, 11305, 1006, 2851, 1007, 2030, 3335, 3270, 2051, 4329, 2305, 7192, 2047, 2671, 23713, 7140, 2571, 1006, 2305, 1007, 1018, 1007, 2522, 21338, 2595, 3514, 1011, 2489, 11087, 1011, 11052, 9496, 6774, 2843, 3258, 1006, 2851, 1998, 2412, 2060, 2305, 1007, 2030, 2522, 21338, 2595, 7209, 2053, 9496, 12227, 5785, 11585, 7308]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm4-Ma72ybJK",
        "colab_type": "text"
      },
      "source": [
        "### Step 5-2: Required Formatting\n",
        "\n",
        "- 각 문장의 처음과 끝에 special token 더하기\n",
        "- 각 문장을 maximum length 만큼 자르고 padding token 채워주기\n",
        "- 각 문장에서 padding token 과 실제 token 들 구분하기 위한 attention masking 적용\n",
        "\n",
        "#### Special Tokens\n",
        "\n",
        "- `[SEP]`: 모든 문장 뒤에 `[SEP]` 더하기\n",
        "- `[CLS]`: 문장의 앞에 `[CLS]` 더하기\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/bert_clf.png?raw=true\" width=\"50%\" height=\"40%\" title=\"Bert4Clf\" alt=\"Bert4Clf\"></img></center>\n",
        "\n",
        "> The first token of every sequence is always a special classification token([CLS]). The final hidden state corresponding to this token is used as **the aggregate sequence representation for classification tasks**.\n",
        "> _(from the BERT paper)_\n",
        "\n",
        "\n",
        "#### Sentence Length & Attention Mask\n",
        "\n",
        "실제 데이터에 있는 문장들의 길이는 천차만별입니다. 이를 위해서 BERT 는 아래의 과정을 통해 해결합니다. \n",
        "\n",
        "- 모든 문장들은 하나의 고정된 길이인 max_len 를 지녀야하고, 이를 위해서 max_len 보다 긴 문장의 경우에는 잘라줍니다. 실제 문장의 길이가 max_len 보다 작은 경우에는 남은 부분을 padding token `[PAD]` 으로 채워줍니다.\n",
        "  - `[PAD]`: BERT 사전에서 index 0 에 해당\n",
        "- max_len 는 512 tokens 입니다.\n",
        "\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/bert_pad.png?raw=true\" width=\"60%\" height=\"50%\" title=\"Bert4Pad\" alt=\"Bert4Pad\"></img></center>\n",
        "\n",
        "- **Attention mask**: 0과 1을 이용해 토큰이 `[PAD]` 인지 실제 값인지를 구분해주기 위한 binary tensor 값입니다.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDJ4ZBtizGK5",
        "colab_type": "text"
      },
      "source": [
        "#### Sentences to IDs\n",
        "\n",
        "`tokenizer.encode` 함수를 이용하여 모든 문장들에 대해 위의 과정들을 한꺼번에 처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qArPy88KybJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "27d141ef-dec2-4fb0-e280-3f4780fe34dc"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence\n",
        "for sent in train_data:\n",
        "    # 'encode' will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the '[CLS]' token to the start.\n",
        "    #   (3) Append the '[SEP]' token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    \n",
        "    encoded_sent = tokenizer.encode(sent, \n",
        "                                    add_special_tokens=True,\n",
        "                                    max_length = 64)\n",
        "    \n",
        "    # Add the encoded sentence to the list\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print train data[0]\n",
        "print(\"Original: \", train_data[0])\n",
        "print()\n",
        "print(\"Token IDs: \", input_ids[0])\n",
        "\n",
        "# Print special tokens and tokenized sentence\n",
        "print(\"\\n[CLS] token: {:}, ID: {:}\".format(tokenizer.cls_token, tokenizer.cls_token_id))\n",
        "print(\"\\n[PAD] token: {:}, ID: {:}\".format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "print(\"\\n[SEP] token: {:}, ID: {:}\".format(tokenizer.sep_token, tokenizer.sep_token_id))\n",
        "print(\"\\nTokenized: \", tokenizer.convert_ids_to_tokens(input_ids[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  I never thought that I would find the right moisturizer for my skin. I have combination skin with large pores that get gunked up if I neglect them and I ve struggled for some time to find a product that would provide sufficient moisture without breaking me out or turning my face into an oil-slick. This is truly a holy grail moisturizer for me and has a nice face feel and natural herbal scent. Will definitely repurchase!  I m a 30 something multi-ethnic muxer and a recent convert to korean beauty. This is my new routine and my skin has never felt or looked bettter!  1) Banila Co Clean It Zero Reservatrol 2) Neogen Green Tea Real Fresh Foam Cleanser 3) MISSHA Time Revolution First Treatment Essence (Morning) or MISSHA Time Revolution Night Repair New Science Ampoule (Night) 4) Cosrx Oil-Free Ultra-Moisturizing Lotion (Morning and ever OTHER night) or Cosrx Ultimate Nourishing Rice Overnight Mask\n",
            "\n",
            "Token IDs:  [101, 1045, 2196, 2245, 2008, 1045, 2052, 2424, 1996, 2157, 11052, 9496, 6290, 2005, 2026, 3096, 1012, 1045, 2031, 5257, 3096, 2007, 2312, 18499, 2229, 2008, 2131, 3282, 8126, 2039, 2065, 1045, 19046, 2068, 1998, 1045, 2310, 6915, 2005, 2070, 2051, 2000, 2424, 1037, 4031, 2008, 2052, 3073, 7182, 14098, 2302, 4911, 2033, 2041, 2030, 3810, 2026, 2227, 2046, 2019, 3514, 1011, 13554, 102]\n",
            "\n",
            "[CLS] token: [CLS], ID: 101\n",
            "\n",
            "[PAD] token: [PAD], ID: 0\n",
            "\n",
            "[SEP] token: [SEP], ID: 102\n",
            "\n",
            "Tokenized:  ['[CLS]', 'i', 'never', 'thought', 'that', 'i', 'would', 'find', 'the', 'right', 'moist', '##uri', '##zer', 'for', 'my', 'skin', '.', 'i', 'have', 'combination', 'skin', 'with', 'large', 'por', '##es', 'that', 'get', 'gun', '##ked', 'up', 'if', 'i', 'neglect', 'them', 'and', 'i', 've', 'struggled', 'for', 'some', 'time', 'to', 'find', 'a', 'product', 'that', 'would', 'provide', 'sufficient', 'moisture', 'without', 'breaking', 'me', 'out', 'or', 'turning', 'my', 'face', 'into', 'an', 'oil', '-', 'slick', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKm4AQMFybJP",
        "colab_type": "text"
      },
      "source": [
        "#### Padding & Truncating\n",
        "\n",
        "`tf.keras.preprocessing.sequence.pad_sequences` 를 이용하여 **MAXLEN** 만큼 padding 과정을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvi1_q33ybJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9e0a11c-11f5-4976-9f34-845af834d32f"
      },
      "source": [
        "print(\"Max length: \", max([len(each) for each in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTelEtVNybJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7ff09882-4045-41d2-93e4-723a47717d60"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
        "\n",
        "MAXLEN = 64\n",
        "\n",
        "input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, \n",
        "                                                          maxlen=MAXLEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.2.0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJnT5boqybJY",
        "colab_type": "text"
      },
      "source": [
        "#### Attention Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maKvU-KKybJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence\n",
        "for sent in input_ids:\n",
        "    # Create the attention mask.\n",
        "    #  - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #  - If a token ID is not 0 ( > 0), then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISSN2XpEybJc",
        "colab_type": "text"
      },
      "source": [
        "#### Training & Validation Split\n",
        "\n",
        "`sklearn` 라이브러리에 `train_test_split` 함수를 이용하여 amazon review dataset 의 90% 는 training 으로 10% 는 validation 으로 나눠줍니다.\n",
        "\n",
        "- `random_state`: reproducibility 를 위함\n",
        "\n",
        "*Note: 아래 코드 블럭을 두 번 이상 실행시키면서 나오는 출력값을 확인해보세요.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTLBXYLTybJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2bca8811-f68b-448b-86fa-02a3f2b6439c"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, train_label, random_state=2018, test_size=0.1)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, valid_masks, _, _ = train_test_split(attention_masks, train_label, random_state=2018, test_size=0.1)\n",
        "\n",
        "# print train_inputs, valid_inputs\n",
        "print(train_inputs[:1])\n",
        "print(train_masks[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  101  4149  2023  2043  2559  2005  2227  3688  3647  1999 10032  1012\n",
            "   1045  2293  2009  1998  2097  3613  2000  2224  2035  1996  2051  2085\n",
            "   1012   102     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_jmnF2IybJj",
        "colab_type": "text"
      },
      "source": [
        "#### Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hFzBxvyybJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required data type for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "valid_inputs = torch.tensor(valid_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "valid_labels = torch.tensor(valid_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "valid_masks = torch.tensor(valid_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J9aJtLU96be",
        "colab_type": "text"
      },
      "source": [
        "PyTorch 의 `DataLoader` class 를 이용하여 amazon review dataset 에 대한 `iterator` 를 생성합니다.\n",
        "\n",
        "- `loop` 랑은 다르게 학습하는 동안에 메모리를 효율적으로 사용 가능\n",
        "- `TensorDataset`: tensor 를 입력받아 dataset 형태로 변환해주는 함수\n",
        "- `RandomSampler`: 입력 dataset 에 element 들의 index 를 무작위로 샘플링하는 함수\n",
        "- `SequentialSampler`: 입력 dataset 에 element 들의 index 를 순차적으로 샘플링하는 함수\n",
        "- `DataLoader`: dataset 과 sampler 를 이용하여 주어진 dataset 에 대하여 배치사이즈만큼 데이터를 반환해주는 함수\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhbYgxdvybJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, we recommend a batch size of 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR7FaNXOybJu",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Train our classification model\n",
        "\n",
        "Pre-train 된 BERT 모델을 불러와서 그 위에 single linear layer 하나를 올립니다. 그리고 전체 모델을 fine-tuning 을 진행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxNAGHYwybJv",
        "colab_type": "text"
      },
      "source": [
        "### Step 6-1: BertForSequenceClassification\n",
        "\n",
        "`huggingface` 라이브러리에서 제공하는 `BertForSequenceClassification` 모델을 사용하면 우리가 원하는 모델을 얻을 수 있습니다. 즉, pre-train BERT 모델 위에 single linear layer 하나가 더해져있는 모델을 불러옵니다. 따라서, 해당 모델을 우리가 원하는 task 에 맞게 end-to-end 방식으로 fine-tuning 을 진행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7JYZMxEybJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "37876a2ec60a44af94dd8ab3e4079be3",
            "7f88f56a43eb4ada9a20b69430f25c84",
            "7d1154c8f1334c9ab48b42902f284829",
            "1a3d3d5da9e04390bd5e0ab64c6fd9df",
            "debe4481017b4088ae3fa548980f5959",
            "b2c0af1d01cd4e6eb5bb6d252a213794",
            "e4b5c56e4f1040e5a2eda87973aa6da4",
            "c9a4f4d18c174a1c9765b71ce03cf9a4",
            "a80a87fb9917495c8ceee704cacdaec3",
            "a752a634ff6247d1bf933284d3c705b9",
            "8e9d47f660674404be31de12e74baff6",
            "4e8768d158e346cc8ed560dbd17f372f",
            "24bcb506a97d4ce8878d4078a6be2f00",
            "956ae416a1b045139e96aca8141a4561",
            "e9892c53bf3143719dc4514e5f5c2737",
            "e56a5f45dacf46f9a1e357a1fa7452a1"
          ]
        },
        "outputId": "44384ee2-8682-41c1-e083-3f35dfb037b4"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassfication, the pretrained BERT model \n",
        "# with a single linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab\n",
        "                                                      num_labels = 2, # The number of output labels 2 for binary classification\n",
        "                                                                      # You can increase this for multi-class tasks\n",
        "                                                      output_attentions = False, # whether the model returns attentions weight (correponding to multi-head self attentions)\n",
        "                                                      output_hidden_states = False) # whether the model returns all hidden states\n",
        "\n",
        "# Tell PyTorch to run this model on the GPU\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37876a2ec60a44af94dd8ab3e4079be3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a80a87fb9917495c8ceee704cacdaec3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX9bftmNybJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "82d84746-6918-420c-d84f-a2edb049d134"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print(\"The BERT model has {:} different named parameters.\\n\".format(len(params)))\n",
        "print(\"=== Embedding Layer ===\\n\")\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print(\"\\n==== First Transformer ====\\n\")\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print(\"\\n==== Output Layer====\\n\")\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "=== Embedding Layer ===\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acXpmSC7ybJ5",
        "colab_type": "text"
      },
      "source": [
        "### Step 6-2: Optimizer & Learning Rate Scheduler\n",
        "\n",
        "- `optimizer`: 모델의 loss function 을 최소화되게 하는 모델의 파라미터들을 찾는 알고리즘\n",
        "- `learning rate scheduler`: learning rate 를 조절해주는 방법\n",
        "  - `learning rate warmup`: 초기에 learning rate 를 0 으로 설정하고 이를 일정 기간동안 heurisitc 하게 키워주는 방식 (*초기값이 너무 크면 학습이 불안정*)\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/warmup.png?raw=true\" width=\"50%\" height=\"50%\"  title=\"warmup\" alt=\"warmup\"></img></center>\n",
        "\n",
        "*이미지 출처: https://hoya012.github.io/blog/Bag-of-Tricks-for-Image-Classification-with-Convolutional-Neural-Networks-Review/*\n",
        "\n",
        "- `learning rate warmup` 관련 논문: https://arxiv.org/abs/1812.01187"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN8StKalybJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for \"Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvTMmRTvybJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62cf9e63-bdca-4e31-f6d8-5061dde89d2b"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (we recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "print(len(train_dataloader))\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdPUjq3GybKA",
        "colab_type": "text"
      },
      "source": [
        "### Step 6-3: Training Loop\n",
        "\n",
        "**Pipeline of training machine learning systems**\n",
        "\n",
        "- **Collect a data**: training/validation/test\n",
        "  - training: 실제 학습 용도\n",
        "  - validation: overfitting 방지 용도\n",
        "  - test: 실제 평가 용도\n",
        "\n",
        "- **Hypothesis set**: Design a network architecture\n",
        "\n",
        "- **Loss function**: Define a loss (objective) function\n",
        "\n",
        "- **optimize loss function**\n",
        "  - Automatic backpropagation: Compute the minibatch gradient\n",
        "  - Optimization: Update the parameters (e.g. Stochastic Gradient Descent)\n",
        "  - Earlystopping: An efficient way to prevent overfitting\n",
        "  - Adaptive learning rate\n",
        "\n",
        "위의 과정을 자세히 살펴보겠습니다.\n",
        "\n",
        "#### **Collect a data**\n",
        "\n",
        "먼저, 학습시키기 위해서는 데이터가 필요합니다. 이를 위해 데이터를 수집합니다. 이 경우에 직접 크롤링을 통해 데이터를 수집할 수도 있지만, 보통은 benchmark 처럼 기존에 표준처럼 사용되는 데이터를 사용합니다. 이렇게 수집한 이후에는 데이터를 train/validation/test 3개의 데이터셋으로 나눕니다. Training dataset 은 실제 모델의 학습을 위해 필요합니다. Valdiation dataset 은 검증 데이터셋으로써, 모델이 학습 도중에 너무 학습 데이터만 기억하게 되는 overfitting (memorization) 이 일어나는 것을 방지하기 위해 필요합니다. Test dataset 은 실제 학습된 모델의 성능을 평가하기 위해 필요합니다.\n",
        "\n",
        "#### **Hypothesis set**\n",
        "\n",
        "데이터를 수집한 이후에는 주어진 task 에 대해서 어떤 모델 (neural network) 를 사용 혹은 고안할지 결정합니다. 예를 들어, 이미지가 고양이인지 강아지인지 분류하는 문제에서는 hypothesis set 은 [VGGnet], [GoogLeNet], [ResNet] 등이 포함될 수 있습니다. 즉, hypothesis set 은 무한 (infinite) 합니다.\n",
        "\n",
        "#### **Loss function**\n",
        "\n",
        "어떤 모델을 사용할지 결정하였으면, 해당 모델에서 loss function 을 설계합니다. 예를 들어, classification 문제의 경우에는 hinge loss, log loss 등이 있고, regression 문제의 경우에는 mean squared error (MSE), mean absolute error, robust loss 등이 있습니다. 그러나 대부분의 딥러닝 모델들은 **distribution-based loss function** 을 사용합니다. Distribution-based loss function 의 distribution 은 입력 x 가 주어졌을 때, 출력 y 가 특정 y' 값일 경우가 얼마나 가능한지 (혹은 그럴듯한지) 를 확인합니다. \n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/dist_loss.png?raw=true\" width=\"40%\" height=\"30%\"  title=\"dist_loss\" alt=\"dist_loss\"></img></center>\n",
        "    \n",
        "위의 수식이 distribution-based loss function 의 distribution 에 해당합니다. 그렇다면, 등식의 우변항이 어떤 종류의 문제이냐에 따라 distribution 이 달라집니다.\n",
        "\n",
        "- Binary classification: Bernoulli distribution\n",
        "- Multiclass classification: Categorical distribution\n",
        "- Linear regression: Gaussian distribution\n",
        "- Multimodal linear regression: Mixture of Gaussians\n",
        "\n",
        "이렇게 distribution 을 정하고 나면, 위의 conditional probability 수식이 training data 에 대해서 **maximally likely** 해야합니다. 아래의 수식에 해당합니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/log_prob.png?raw=true\" width=\"50%\" height=\"40%\"  title=\"log_prob\" alt=\"log_prob\"></img></center>\n",
        "\n",
        "위의 수식이 **log-likelihood** 라고 부르고, 해당 수식을 최대화 되게끔 학습이 이루어집니다. 그런데 Loss function 은 최소화되어야하므로 아래의 수식처럼 log-likelihood 앞에 (-) 를 붙입니다. 이를 **negative log-likelihood** 라고 부르고, distribution-based loss function 이 됩니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/nll.png?raw=true\" width=\"40%\" height=\"30%\"  title=\"nll\" alt=\"nll\"></img></center>\n",
        "\n",
        "#### **optimizer loss function**\n",
        "\n",
        "이렇게 loss function 을 결정한 이후에, 해당 loss 값을 최소화시키기 위해 어떻게 해야할까요? 고등수학으로 돌아가보면, 미분가능한 함수에서 최솟값은 미분값이 0인 지점이라는 것을 알 수 있습니다. 이 원리를 이용해서, gradient-based optimization 방법이 제안되었습니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/gradient.png?raw=true\" width=\"60%\" height=\"50%\"  title=\"gradient\" alt=\"gradient\"></img></center>\n",
        "\n",
        "Gradient-based optimization 알고리즘을 살펴보면 아래와 같습니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/gradient_alg.png?raw=true\" width=\"60%\" height=\"50%\"  title=\"gradient_alg\" alt=\"gradient_alg\"></img></center>\n",
        "\n",
        "그러나 해당 방법은 **모든 데이터에 대해서 한번에 gradient 를 계산해야하므로 비용이 많이 든다**는 문제점이 있습니다. 이를 해결하기 위해, 전체 데이터 셋에서 랜덤하게 하나만 샘플링해서 gradient 를 계산하는 방법인 **stochastic gradient descent** 방법이 제안되었습니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/stochastic_alg.png?raw=true\" width=\"60%\" height=\"50%\"  title=\"stochastic_alg\" alt=\"stochastic_alg\"></img></center>\n",
        "\n",
        "위의 방법은 gradient-based optimization 방법보다는 효율적으로 계산이 가능하지만, **굉장히 noisy 하다**는 문제점이 있습니다. 만약 데이터 하나가 전체 데이터셋을 나타내는 표본이 아닌 경우에는, noise 가 있는 데이터 하나를 샘플링하게 되는 것이고 그렇게 되면 optimization 자체는 noise 가 있을 수 밖에 없습니다. 따라서, 데이터 하나를 샘플링하는 것이 아니라 묶음 단위로 하는 방법인 **minibatch stochastic gradient descent** 방법이 제안되었습니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/mini_stochastic.png?raw=true\" width=\"60%\" height=\"50%\"  title=\"mini_stochastic\" alt=\"mini_stochastic\"></img></center>\n",
        "\n",
        "이렇게 모델의 학습을 진행하면 학습 모델의 loss 값이 계속 낮아지도록 학습이 이루어집니다. 그런데, 모델의 training loss 값이 낮은게 정말 좋은 모델을 의미할까요?\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/overfitting.png?raw=true\" width=\"70%\" height=\"60%\"  title=\"overfitting\" alt=\"overfitting\"></img></center>\n",
        "\n",
        "위의 그림을 보시면, 오른쪽 모델의 training loss 가 제일 낮은 것을 확인할 수 있습니다. 그러나 해당 모델이 제일 좋다고는 말할 수 없습니다. 왜냐하면 모델이 학습 데이터에 대해서는 좋은 성능을 보일 수 있어도, 너무 학습 데이터에만 과하게 학습이 되어서 새로운 (처음보는) 데이터가 들어왔을 때는 성능이 좋지 않을 수 있습니다. 이런 문제를 **overfitting** 이라고 부릅니다. Overfitting 현상은 모델이 학습 데이터를 일종의 **\"memorize\"** 현상이라고 볼 수 있습니다. **보통 training loss 는 낮은데, test error 는 높아질 때 발생합니다.** 또한, 모델의 parameter 가 training data 수보다 많은 경우에 일반적으로 발생합니다.\n",
        "\n",
        "이를 해결하는 방법 (Regularization) 이 대표적으로 **weight decay, dropout, early stopping** 이 있습니다. \n",
        "\n",
        "- **weigth decay**: Penalize complex solution using **additional constraints**\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/weight_decay.png?raw=true\" width=\"70%\" height=\"60%\"  title=\"weight_decay\" alt=\"weight_decay\"></img></center>\n",
        "\n",
        "- **Dropout**: **Randomly turn off** activations with some probability p\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/dropout.png?raw=true\" width=\"70%\" height=\"60%\"  title=\"dropout\" alt=\"dropout\"></img></center>\n",
        "\n",
        "- **Early stopping**: Stop training once the validation loss starts to increase\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/earlystopping.png?raw=true\" width=\"70%\" height=\"60%\"  title=\"earlystopping\" alt=\"earlystopping\"></img></center>\n",
        "\n",
        "*이미지 출처: MIT 6.S191: Introduction to Deep Learning*\n",
        "\n",
        "이렇게 Regularization 의 대표적인 3가지 기법들을 알아보았습니다. 그렇다면, 실제로 minibatch stochastic gradient descent 가 어떻게 이루어질까요?\n",
        "\n",
        "1. random 하게 batch 단위의 데이터를 불러오기\n",
        "2. minibatch gradient 계산\n",
        "3. 모델의 parameter 들 업데이트\n",
        "4. validation loss 가 더이상 좋아지지 않을 때까지 1, 2, 3 과정 반복\n",
        "\n",
        "[Adam optimizer]: https://arxiv.org/abs/1412.6980\n",
        "\n",
        "stochastic gradient descent 방법은 learning rate 를 고정시키고 학습을 진행하는데, 고정시킨 learning rate 값이 모델의 학습을 불안정 시키게 할 수 있습니다. 이를 위해 adaptive 하게 learning rate 를 조절하는 optimization 방법이 제안되었습니다. 대표적으로 **[Adam optimizer]** 가 있습니다. 현재 제일 많이 사용되는 optimizer 입니다. 본 실습에서도 Adam optimizer 를 사용할 것입니다. 아래는 optimizer 관련 계보입니다.\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/optimizers.png?raw=true\" width=\"70%\" height=\"60%\"  title=\"optimizers\" alt=\"optimizers\"></img></center>\n",
        "\n",
        "\n",
        "\n",
        "#### **본 실습에서 학습 과정**\n",
        "\n",
        "- `DataLoader` 를 통해 data 와 label 배치사이즈 단위로 가져오기\n",
        "- Forward pass: data 와 label 을 `BertForSequenceClassification` 모델에 입력으로 주기\n",
        "- Backward pass:\n",
        "  - minibatch gradient 계산 (backpropagation)\n",
        "  - 모델의 파라미터들 업데이트 (optimization)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pigy1CqrybKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=-1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXBpr-HAybKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Take a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0QRDrYcybKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible\n",
        "def set_seed(seed_val):\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOCgIIrpybKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4590879-0267-4af6-9b53-3e88c03cf16a"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 42\n",
        "set_seed(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
        "    print('Training...')\n",
        "    \n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    \n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0.\n",
        "    \n",
        "    # Put the model into training mode.\n",
        "    # Don't be mislead -- the call to 'train' just changes the \"mode\", it doesn't \"perform\" the training.\n",
        "    # 'dropout' and 'bachnorm' layers behave differently during training vs test\n",
        "    model.train()\n",
        "    \n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress\n",
        "            print(\"Batch {:>5,} of {:>5,}. Elapsed: {:}.\".format(step, len(train_dataloader), elapsed))\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value from the tensor.\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        \n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.        \n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "    \n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "    \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on our validation set.\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    \n",
        "    t0 = time.time()\n",
        "    \n",
        "    # Put the model in evaluation mode -- the dropout layers behave differently during evaluation\n",
        "    model.eval()\n",
        "    \n",
        "    # Tracking variables\n",
        "    eval_loss, eval_acc = 0., 0.\n",
        "    \n",
        "    # Evaluate data for one epoch\n",
        "    for valid_step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have not provided labels.\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            \n",
        "        # Get the \"logits\" output by the model.\n",
        "        # The \"logits\" are the output values prior to applying an activation function like the softmax\n",
        "        logits = outputs[0]\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_acc = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_acc += tmp_eval_acc        \n",
        "    \n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"Accuracy: {0:.2f}\".format(eval_acc / (valid_step + 1)))\n",
        "    print(\"Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Batch    40 of   302. Elapsed: 0:00:26.\n",
            "Batch    80 of   302. Elapsed: 0:00:51.\n",
            "Batch   120 of   302. Elapsed: 0:01:16.\n",
            "Batch   160 of   302. Elapsed: 0:01:42.\n",
            "Batch   200 of   302. Elapsed: 0:02:07.\n",
            "Batch   240 of   302. Elapsed: 0:02:33.\n",
            "Batch   280 of   302. Elapsed: 0:02:58.\n",
            "\n",
            "Average training loss: 0.17\n",
            "Training epoch took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.97\n",
            "Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Batch    40 of   302. Elapsed: 0:00:25.\n",
            "Batch    80 of   302. Elapsed: 0:00:51.\n",
            "Batch   120 of   302. Elapsed: 0:01:16.\n",
            "Batch   160 of   302. Elapsed: 0:01:42.\n",
            "Batch   200 of   302. Elapsed: 0:02:07.\n",
            "Batch   240 of   302. Elapsed: 0:02:33.\n",
            "Batch   280 of   302. Elapsed: 0:02:58.\n",
            "\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.97\n",
            "Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Batch    40 of   302. Elapsed: 0:00:25.\n",
            "Batch    80 of   302. Elapsed: 0:00:51.\n",
            "Batch   120 of   302. Elapsed: 0:01:16.\n",
            "Batch   160 of   302. Elapsed: 0:01:41.\n",
            "Batch   200 of   302. Elapsed: 0:02:07.\n",
            "Batch   240 of   302. Elapsed: 0:02:32.\n",
            "Batch   280 of   302. Elapsed: 0:02:57.\n",
            "\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:03:11\n",
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.97\n",
            "Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Batch    40 of   302. Elapsed: 0:00:25.\n",
            "Batch    80 of   302. Elapsed: 0:00:51.\n",
            "Batch   120 of   302. Elapsed: 0:01:16.\n",
            "Batch   160 of   302. Elapsed: 0:01:41.\n",
            "Batch   200 of   302. Elapsed: 0:02:06.\n",
            "Batch   240 of   302. Elapsed: 0:02:32.\n",
            "Batch   280 of   302. Elapsed: 0:02:57.\n",
            "\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:03:11\n",
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.97\n",
            "Validation took: 0:00:07\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HEWjeywybKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "24f9f361-6db2-4f7d-832f-b2c7b622c3d1"
      },
      "source": [
        "# visualize training loss over all batches\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVQTc7Yd5wR8",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Performance on Test set\n",
        "\n",
        "- `sklearn` 라이브러리의 `classification_report` 함수 이용하여 **accuracy, precision, recall, f1 score** 평가 지표를 이용하여 test dataset 에 대해 성능 확인\n",
        "  - dataset 의 label 이 균형적인 경우 (balanced data): **accuracy**\n",
        "  - dataset 의 label 이 불균형적인 경우 (imbalanced data): **f1 score**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE5hAam9WjWf",
        "colab_type": "text"
      },
      "source": [
        "### Step 7-1: Load Amazon Review Test Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQkChrxk5YLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a669db3a-72a1-4030-eb41-9f8526970df1"
      },
      "source": [
        "# pickle 모듈로 파일 load\n",
        "with open(test_data, 'rb') as f:\n",
        "    test_data = pc.load(f)\n",
        "with open(test_label, 'rb') as f:\n",
        "    test_label = pc.load(f)\n",
        "\n",
        "print(\"Size of test data: {}\".format(len(test_data)))\n",
        "print(\"Size of test label: {}\".format(len(test_label)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of test data: 174\n",
            "Size of test label: 174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8GJHfrEW39t",
        "colab_type": "text"
      },
      "source": [
        "### Step 7-2: Tokenization & Input Formatting\n",
        "\n",
        "본 단계에서는 fine-tuning layer 까지 학습한 BERT 모델의 입력 format 에 맞게 amazon review test dataset 을 변환해줍니다. (*위에서 진행한 방법과 동일*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIg14zYC50F1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_data:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=MAXLEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence\n",
        "for sent in input_ids:\n",
        "    # Create the attention mask.\n",
        "    #  - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #  - If a token ID is not 0 ( > 0), then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_label)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-dlllY7XkJ-",
        "colab_type": "text"
      },
      "source": [
        "### Step 7-3: Evaluate on Test Set\n",
        "\n",
        "- `.detach()`: tensor 가 기록을 추적하는 것을 중단하게 해주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PK69aZG6kWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "787537cb-3689-4abf-c762-1ec8828c488a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(np.argmax(logits, axis=1).flatten())\n",
        "  true_labels.extend(label_ids.flatten())\n",
        "\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 174 test sentences...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3o8SfUnV--K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a1733371-7b60-4128-d487-0c3fd4092b42"
      },
      "source": [
        "# accuracy, precision, recall, f1 score 성능 확인\n",
        "from sklearn.metrics import classification_report\n",
        "    \n",
        "target_names = ['negative', 'positive']\n",
        "\n",
        "print(classification_report(true_labels, predictions, digits=4, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.9474    0.8276    0.8834        87\n",
            "    positive     0.8469    0.9540    0.8973        87\n",
            "\n",
            "    accuracy                         0.8908       174\n",
            "   macro avg     0.8972    0.8908    0.8904       174\n",
            "weighted avg     0.8972    0.8908    0.8904       174\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFz-r33cZM5q",
        "colab_type": "text"
      },
      "source": [
        "## Appendix\n",
        "\n",
        "**Timeline for some major NLP projects before BERT**\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/before_bert.png?raw=true\" width=\"100%\" height=\"100%\" title=\"beforeBERT\" alt=\"beforeBERT\"></img></center>\n",
        "\n",
        "**Timeline for projects after BERT**\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/after_bert.png?raw=true\" width=\"100%\" height=\"100%\" title=\"afterBERT\" alt=\"afterBERT\"></img></center>\n",
        "\n",
        "**GLUE benchmark leaderboard**\n",
        "(*2020.02.04 기준*)\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/current_glue.png?raw=true\" width=\"100%\" height=\"100%\" title=\"currentGLUE\" alt=\"currentGLUE\"></img></center>\n",
        "\n",
        "\n",
        "**SuperGLUE benchmark leaderboard**\n",
        "(*2020.02.04 기준*)\n",
        "\n",
        "<center><img src=\"https://github.com/passing2961/KEMC/blob/master/superglue.png?raw=true\" width=\"100%\" height=\"100%\" title=\"SuperGLUE\" alt=\"SuperGLUE\"></img></center>\n",
        "\n",
        "\n",
        "\n",
        "*이미지 출처: https://towardsdatascience.com/2019-year-of-bert-and-transformer-f200b53d05b9*\n",
        "\n",
        "\n",
        "**Paper related with BERT**\n",
        "\n",
        "- Transformer-XL: https://arxiv.org/abs/1901.02860\n",
        "- GPT-2: https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n",
        "- ERNIE: https://arxiv.org/abs/1905.07129\n",
        "- XLNet: https://arxiv.org/abs/1906.08237\n",
        "- RoBERTa: https://arxiv.org/abs/1907.11692\n",
        "- CTRL: https://arxiv.org/abs/1909.05858\n",
        "- ALBERT: https://arxiv.org/abs/1909.11942"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qH_FBEWslsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}